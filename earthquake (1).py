# -*- coding: utf-8 -*-
"""EarthQuake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_bwGr2H_Qelj68BR2qgKQrrd0tASqJ3O

# ***`Import Datasets`***
"""

import pandas as pd
from google.colab import data_table
data_table.enable_dataframe_formatter()

# Mount Google Drive to Colab to access files from Drive
from google.colab import drive
drive.mount('/content/drive')

# Update the file path to point to the location in your Google Drive
file_path = '/content/drive/My Drive/JK EarthQuake 100Years.csv'  # Update with your file's location

# Read CSV file with space delimiter
df = pd.read_csv(file_path, delimiter=r'\s+')

# Print the first 5 rows of the data frame
display(df)

"""# ***`Preprocessing`***"""

import pandas as pd
from google.colab import data_table
data_table.enable_dataframe_formatter()

# Mount Google Drive to Colab to access files from Drive
from google.colab import drive
drive.mount('/content/drive')

# Update the file path to point to the location in your Google Drive
file_path = '/content/drive/My Drive/JK EarthQuake 100Years.csv'  # Update with your file's location

# Read CSV file, explicitly specifying the delimiter or using a more robust method
# If the delimiter is a comma, use:
df = pd.read_csv(file_path)
# If the delimiter is not consistent, consider using:
# df = pd.read_csv(file_path, delim_whitespace=True) # For whitespace delimiters
# or manually specifying the delimiter based on the file's structure

# Print the first 5 rows of the data frame to verify correct parsing
display(df)


new_column_names = ["Date(YYYY/MM/DD)",  "Time(UTC)", "Latitude(deg)", "Longitude(deg)", "Depth(km)", "Magnitude(ergs)"]

# Assign new column names only if the number of columns matches
if len(df.columns) == len(new_column_names):
    df.columns = new_column_names
    ts = pd.to_datetime(df["Date(YYYY/MM/DD)"] + " " + df["Time(UTC)"])
    df = df.drop(["Date(YYYY/MM/DD)", "Time(UTC)"], axis=1)
    df.index = ts
    display(df)
else:
    print(f"Error: Number of columns in DataFrame ({len(df.columns)}) does not match the number of new column names ({len(new_column_names)}).")
    print("Please check the delimiter used when reading the CSV file.")

"""# ***`Lat and Long Bar graphs`***"""

# Import necessary libraries
import pandas as pd
from google.colab import drive, data_table
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# Mount Google Drive
drive.mount('/content/drive')
data_table.enable_dataframe_formatter()

# File path to the dataset in Google Drive
file_path = '/content/drive/MyDrive/JK EarthQuake 100Years.csv'

# Function to handle lines with inconsistent delimiters
def handle_bad_lines(line):
    """Handles lines with inconsistent delimiters by joining extra fields."""
    line_str = ' '.join([str(item) if item is not None else '' for item in line])
    fields = line_str.strip().split(',', 13)
    if len(fields) > 13:
        fields[12] = ','.join(fields[12:])
        fields = fields[:13]  # Keep only the first 13 fields
    return fields

# Try to load the dataset
try:
    df = pd.read_csv(file_path, engine='python', on_bad_lines=handle_bad_lines, header=None)

    # Assign column names
    df.columns = ['Time', 'Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'Magnitude(ergs)']

    # Convert relevant columns to numeric, handling conversion errors
    for col in ['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'Magnitude(ergs)']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    # Drop rows with missing values in the required columns
    df.dropna(subset=['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'Magnitude(ergs)'], inplace=True)

except FileNotFoundError:
    print(f"Error: File not found at {file_path}. Please check the path and ensure the file is in your Google Drive.")

# Select relevant columns for features (X) and target (y)
X = df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)']]
y = df['Magnitude(ergs)']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Feature scaling using StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize models: Linear Regression, SVM, and Random Forest
models = {
    "Linear Regression": LinearRegression(),
    "SVM": SVR(kernel='rbf'),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=0)
}

# Store model performance results
results = {"Model": [], "R^2 Score": [], "Mean Squared Error": [], "Mean Absolute Error": []}

# Train and evaluate each model
for model_name, model in models.items():
    # Fit the model
    model.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred = model.predict(X_test_scaled)

    # Calculate R^2, MSE, and MAE
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    # Store the results
    results["Model"].append(model_name)
    results["R^2 Score"].append(r2)
    results["Mean Squared Error"].append(mse)
    results["Mean Absolute Error"].append(mae)

# Convert the results dictionary to a DataFrame
results_df = pd.DataFrame(results)

# Display the results
print("\nModel Performance Results:")
print(results_df)

# Visualize Model Performance: Bar charts for R^2, MSE, and MAE
plt.figure(figsize=(18, 6))

# Plot R^2 Scores
plt.subplot(1, 3, 1)
sns.barplot(x='Model', y='R^2 Score', data=results_df, palette="viridis")
plt.title('R^2 Score for Different Models')
plt.ylabel('R^2 Score')

# Plot Mean Squared Error
plt.subplot(1, 3, 2)
sns.barplot(x='Model', y='Mean Squared Error', data=results_df, palette="magma")
plt.title('Mean Squared Error for Different Models')
plt.ylabel('Mean Squared Error')

# Plot Mean Absolute Error
plt.subplot(1, 3, 3)
sns.barplot(x='Model', y='Mean Absolute Error', data=results_df, palette="coolwarm")
plt.title('Mean Absolute Error for Different Models')
plt.ylabel('Mean Absolute Error')

plt.tight_layout()
plt.show()

# Cross-validation on each model
for model_name, model in models.items():
    cv_scores = cross_val_score(model, X_train_scaled, y_train, scoring='r2', cv=5)
    print(f"\nCross-validated R^2 scores for {model_name}: {cv_scores}")
    print(f"Average R^2 score for {model_name}: {cv_scores.mean()}")

# Data Visualization - Pairplot for feature exploration
sns.pairplot(df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'Magnitude(ergs)']])
plt.show()

# Correlation Matrix to check relationships between features
numeric_df = df.select_dtypes(include=['number'])
correlation = numeric_df.corr()

sns.heatmap(correlation, annot=True, cmap="coolwarm")
plt.show()

# --- Region-Based Analysis for Highest Earthquake Chances ---

# Create regions by grouping based on latitude and longitude (you can adjust the bins size for better granularity)
lat_bins = pd.cut(df['Latitude(deg)'], bins=10)
lon_bins = pd.cut(df['Longitude(deg)'], bins=10)

# Create a new column 'Region' based on these bins
df['Region'] = lat_bins.astype(str) + ' & ' + lon_bins.astype(str)

# Now, group by 'Region' and find the average earthquake magnitude in each region
region_group = df.groupby('Region').agg({
    'Magnitude(ergs)': 'mean',
    'Latitude(deg)': 'mean',
    'Longitude(deg)': 'mean',
    'Depth(km)': 'mean'
}).reset_index()

# Find the region with the highest average earthquake magnitude
max_magnitude_region = region_group.loc[region_group['Magnitude(ergs)'].idxmax()]

# Display the region with the highest earthquake chances
print("\nRegion with the highest earthquake chances:")
print(max_magnitude_region)

# --- Heatmap for the Number of Earthquakes in Each Region ---

# Create a new column 'Earthquake_Count' which stores the number of earthquakes per region
earthquake_count = df.groupby('Region').size().reset_index(name='Earthquake_Count')

# Now, join this back with the region_group dataframe to include the count of earthquakes
region_group_count = pd.merge(region_group, earthquake_count, on='Region')

# Convert 'Earthquake_Count' to integers before plotting
region_group_count['Earthquake_Count'] = region_group_count['Earthquake_Count'].astype(int)

"""# ***`Heatmap Magnitude by region`***"""

# Plot a heatmap of the earthquake magnitude across regions
plt.figure(figsize=(10, 6))
sns.heatmap(region_group.pivot_table(index='Latitude(deg)', columns='Longitude(deg)', values='Magnitude(ergs)', aggfunc='mean'), cmap='YlOrRd')
plt.title('Heatmap of Earthquake Magnitude by Region')
plt.show()

"""# Heatmap Frequency by region"""

# Plot a heatmap showing the number of earthquakes in each region
plt.figure(figsize=(10, 6))

# Create the heatmap with annotations formatted to 2 decimal places
heatmap = sns.heatmap(
    region_group_count.pivot_table(index='Latitude(deg)', columns='Longitude(deg)', values='Earthquake_Count', aggfunc='sum'),
    cmap='coolwarm', annot=True, fmt=".2f", annot_kws={"size": 10, "weight": "bold"}, cbar_kws={'label': 'Earthquake Count'}
)

# Set the tick labels for latitude and longitude with 2 decimal places, avoiding overlap
plt.gca().set_xticklabels([f"{item:.2f}" for item in plt.gca().get_xticks()], rotation=45, ha="right", fontsize=10)
plt.gca().set_yticklabels([f"{item:.2f}" for item in plt.gca().get_yticks()], rotation=0, fontsize=10)

# Title and axis labels
plt.title('Heatmap of Earthquake Occurrences by Region', fontsize=14)
plt.xlabel('Longitude (degrees)', fontsize=12)
plt.ylabel('Latitude (degrees)', fontsize=12)

# Show the plot
plt.tight_layout()
plt.show()

"""# ***`Cluster of Earthquake by Magnitude`***"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# Group by Latitude and Longitude to get the count of earthquakes for each combination
lat_lon_earthquake_count = df.groupby(['Latitude(deg)', 'Longitude(deg)']).size().reset_index(name='Earthquake_Frequency')

# Display the frequency of earthquakes at specific latitude and longitude
print("\n--- Frequency of Earthquakes at Specific Latitude and Longitude ---")
print(lat_lon_earthquake_count)

# Find the area (latitude/longitude) with the highest frequency of earthquakes
max_earthquake_row = lat_lon_earthquake_count.loc[lat_lon_earthquake_count['Earthquake_Frequency'].idxmax()]
highest_earthquake_area = (max_earthquake_row['Latitude(deg)'], max_earthquake_row['Longitude(deg)'])
highest_earthquake_count = int(max_earthquake_row['Earthquake_Frequency'])  # Convert to integer

# Display the area with the highest number of earthquakes
print(f"\n--- Area with the Highest Number of Earthquakes ---")
print(f"Location (Latitude, Longitude): {highest_earthquake_area}")
print(f"Number of earthquakes in this area: {highest_earthquake_count}")

# --- Clustering the Earthquake Frequencies ---

# Define the number of clusters
n_clusters = 4  # You can adjust this number as needed

# Apply KMeans clustering to the latitude and longitude data
kmeans = KMeans(n_clusters=n_clusters, random_state=0)
lat_lon_earthquake_count['Cluster'] = kmeans.fit_predict(lat_lon_earthquake_count[['Latitude(deg)', 'Longitude(deg)']])

# Display the DataFrame with cluster assignments
print("\n--- Data with Earthquake Frequencies and Cluster Assignments ---")
print(lat_lon_earthquake_count)

# --- Future Prediction (Simple Estimate) ---
# Assuming a basic linear growth model to estimate future earthquake counts based on current trends

current_total_earthquakes = lat_lon_earthquake_count['Earthquake_Frequency'].sum()
growth_rate = 0.05  # Assume a 5% annual increase in earthquake frequency (hypothetical value)
years_to_predict = 5
future_earthquake_count = current_total_earthquakes * (1 + growth_rate) ** years_to_predict

print(f"\n--- Predicted Total Number of Earthquakes in {years_to_predict} Years ---")
print(f"Predicted earthquakes: {future_earthquake_count:.2f}")

# --- Visualizing the Earthquake Frequency with Clusters ---

# Plotting a heatmap of earthquake frequency based on Latitude and Longitude with clustering
plt.figure(figsize=(10, 6))

# Pivot the data to create the heatmap with clusters
heatmap_data = lat_lon_earthquake_count.pivot_table(index='Latitude(deg)', columns='Longitude(deg)', values='Earthquake_Frequency', aggfunc='sum')

# Create a heatmap with cluster information as annotations
sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt=".0f", linewidths=0.5, cbar_kws={'label': 'Earthquake Frequency'})

# Set the tick labels for latitude and longitude with 2 decimal places
plt.gca().set_xticklabels([f"{item:.2f}" for item in plt.gca().get_xticks()])
plt.gca().set_yticklabels([f"{item:.2f}" for item in plt.gca().get_yticks()])

plt.title('Clustered Heatmap of Earthquake Frequency by Latitude and Longitude')
plt.show()

# --- Visualizing Clusters ---

# Plot the clusters on a scatter plot
plt.figure(figsize=(10, 6))

# Scatter plot of earthquake locations, colored by clusters
sns.scatterplot(data=lat_lon_earthquake_count, x='Longitude(deg)', y='Latitude(deg)', hue='Cluster', palette='viridis', size='Earthquake_Frequency', sizes=(20, 200))

plt.title('Clusters of Earthquake Frequency by Latitude and Longitude')
plt.xlabel('Longitude(deg)')
plt.ylabel('Latitude(deg)')
plt.legend(title='Cluster')
plt.show()

"""# ***`Notification and Alerts`***"""

!pip install twilio
from twilio.rest import Client

# Your Account SID and Auth Token from twilio.com/console
account_sid = 'AC067babff0a6f945bd85be5a6ab75ffac'  # Replace with your Account SID
auth_token = 'c43946526bd635c3d2a90ad9653a0d43'  # Replace with your Auth Token

client = Client(account_sid, auth_token)

# List of WhatsApp numbers to send the message to
to_numbers = [
    "whatsapp:+919940022199",
    # Add more numbers here if needed
]

# Earthquake safety message
Precautions_message = "Hi this is a security message from The Earthquake cell, are you and your loved ones safe from the recent earthquake? Please let us know if you need any assistance. Stay safe! Do you need any assistance"
precautions_message = """🚨 *Earthquake Safety Precautions* 🚨

1️⃣ *Drop, Cover, and Hold:* Take cover under a sturdy object. Protect your head.
2️⃣ *Stay Indoors:* If inside, stay away from windows, mirrors, and heavy furniture.
3️⃣ *Avoid Elevators:* Use stairs instead if evacuation is necessary.
4️⃣ *If Outside:* Move to an open area away from buildings, trees, and power lines.
5️⃣ *If Driving:* Stop the car safely, away from bridges and overpasses. Stay inside.
6️⃣ *Check for Injuries:* Help others if trained, and seek medical assistance if needed.
7️⃣ *After the Quake:* Expect aftershocks and avoid damaged buildings.

📢 *Stay alert and follow official updates from authorities.* 🚨
"""

# Iterate through the list and send a message to each number
for to_number in to_numbers:
    message = client.messages.create(
        from_='whatsapp:+14155238886',  # Replace with your Twilio WhatsApp number
        body=Precautions_message,  # Using the safety message
        to=to_number
    )
    print(f"Message SID for {to_number}: {message.sid}")

"""# ***`Safety assistance will be required`***"""

from twilio.rest import Client

account_sid = 'AC067babff0a6f945bd85be5a6ab75ffac'
auth_token = 'c43946526bd635c3d2a90ad9653a0d43'
client = Client(account_sid, auth_token)

message = client.messages.create(
  from_='whatsapp:+14155238886',
  body='''Your safty assistance will be provided here
  *Earthquake Safety Precautions* 🚨

1️⃣ *Drop, Cover, and Hold:* Take cover under a sturdy object. Protect your head.
2️⃣ *Stay Indoors:* If inside, stay away from windows, mirrors, and heavy furniture.
3️⃣ *Avoid Elevators:* Use stairs instead if evacuation is necessary.
4️⃣ *If Outside:* Move to an open area away from buildings, trees, and power lines.
5️⃣ *If Driving:* Stop the car safely, away from bridges and overpasses. Stay inside.
6️⃣ *Check for Injuries:* Help others if trained, and seek medical assistance if needed.
7️⃣ *After the Quake:* Expect aftershocks and avoid damaged buildings.

📢 *Stay alert and follow official updates from authorities.* 🚨''',
  to='whatsapp:+919940022199'
)

print(message.sid)

"""# ***`If safety assistance is not required`***"""

from twilio.rest import Client

account_sid = 'AC067babff0a6f945bd85be5a6ab75ffac'
auth_token = 'c43946526bd635c3d2a90ad9653a0d43'
client = Client(account_sid, auth_token)

message = client.messages.create(
  from_='whatsapp:+14155238886',
  body='For assistance you can contact anytime',
  to='whatsapp:+919940022199'
)

print(message.sid)

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Define the file path where you want to save the script
file_path = "/content/drive/MyDrive/app.py"

# Save the script
code = """from flask import Flask, request
from twilio.twiml.messaging_response import MessagingResponse
from flask_ngrok import run_with_ngrok  # To expose local server

app = Flask(__name__)
run_with_ngrok(app)  # Start ngrok when running the app

@app.route("/whatsapp", methods=['POST'])
def whatsapp_reply():

    incoming_msg = request.values.get('Body', '').lower()  # Get the message text
    sender = request.values.get('From', '')  # Get the sender's WhatsApp number

    response = MessagingResponse()

    # Earthquake help message
    help_message = (
    "Earthquake Help Information\n"
    "Stay calm and find a safe spot.\n"
    "Avoid elevators & stand under a sturdy object.\n"
    "If trapped, make noise to signal for help.\n"
    "Contact emergency services if needed.\n"
    "Stay safe!"
)

    response.message(help_message)

    print(f"Replied to {sender}: {help_message}")  # Log response
    return str(response)

if __name__ == "__main__":
    app.run()"""

with open(file_path, "w") as file:
    file.write(code)

print(f"File saved at: {file_path}")

pip install flask-cors

"""# ***`safety alert system`***"""

!pip install twilio
from twilio.rest import Client

# Twilio Credentials
account_sid = 'AC067babff0a6f945bd85be5a6ab75ffac'  # Replace with your Account SID
auth_token = 'c43946526bd635c3d2a90ad9653a0d43'  # Replace with your Auth Token
client = Client(account_sid, auth_token)
twilio_whatsapp_number = 'whatsapp:+14155238886'

# List of recipients
to_numbers = ["whatsapp:+919940022199"]  # Add more numbers if needed

# Earthquake Safety Message
precautions_message = """🚨 *Earthquake Safety Alert* 🚨

Hi, this is a security message from *The Earthquake Cell*. Are you and your loved ones safe from the recent earthquake? Please let us know if you need any assistance. Stay safe!

*Reply with:*
✅ 'YES' - If you need assistance
❌ 'NO' - If you are safe
"""

# Send Initial Message
for to_number in to_numbers:
    message = client.messages.create(
        from_=twilio_whatsapp_number,
        body=precautions_message,
        to=to_number
    )
    print(f"Alert sent to {to_number}: {message.sid}")

# Function to send follow-up response
def send_followup(response, recipient):
    assistance_message = """🚨 *Safety Assistance* 🚨

✅ Your safety assistance will be provided.

📢 *Earthquake Safety Precautions:*
1️⃣ Drop, Cover, and Hold: Take cover under a sturdy object.
2️⃣ Stay Indoors: Avoid windows, mirrors, and heavy furniture.
3️⃣ Avoid Elevators: Use stairs instead.
4️⃣ If Outside: Move to an open area away from buildings and power lines.
5️⃣ If Driving: Stop the car safely and stay inside.
6️⃣ Check for Injuries: Help others and seek medical assistance.
7️⃣ Expect Aftershocks: Avoid damaged buildings.

Stay alert and follow official updates. 🚨"""

    no_assistance_message = "✅ Glad to know you're safe! For any assistance, you can contact us anytime."

    message_body = assistance_message if response.lower() == "yes" else no_assistance_message

    message = client.messages.create(
        from_=twilio_whatsapp_number,
        body=message_body,
        to=recipient
    )
    print(f"Follow-up message sent to {recipient}: {message.sid}")

# Simulating user response (Replace this with actual response handling logic)
user_response = input("Enter user response (YES/NO): ")  # Simulate input from a user
recipient_number = to_numbers[0]  # Example for the first recipient

send_followup(user_response, recipient_number)